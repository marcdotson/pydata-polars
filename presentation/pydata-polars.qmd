---
title: Data Wrangling with Polars
subtitle: |
  | PyData Northern Utah
  | [github.com/marcdotson/pydata-polars](https://github.com/marcdotson/pydata-polars)
author: Marc Dotson
date: 2024-11-20
title-slide-attributes:
  data-background-color: "#486790"
format: 
  revealjs:
    theme: marc.scss     # Modified simple theme.
    slide-number: c/t    # Numbered slides current/total.
    self-contained: true # Render to a single HTML file.
execute:
  eval: false
  echo: true
---

## 

:::: {.columns .v-center}

::: {.column width="40%"}
![](../figures/polars.png){fig-align="center"}
:::

::: {.column width="60%"}
::: {.incremental}
- Newer open source library for data wrangling
- Alternative to Pandas for manipulating DataFrames
- **Fast** -- written in Rust, uses Apache Arrow, built to parallelize and use GPUs, allows for lazy evaluation
- More consistent syntax than Pandas
- Anagram of its query engine (OLAP) and Rust (rs)
:::
:::

::::

## Load Packages and Data

After installing with `pip install polars`, we can import Polars and read in data.

::: {.panel-tabset .scrollable}
## Polars

```{python}
import polars as pl

customer_data = pl.read_csv('data/customer_data.csv')
customer_data
```

## Pandas

```{python}
import pandas as pd

customer_data_pd = pd.read_csv('data/customer_data.csv')
customer_data_pd
```

## R

```{r}
library(tidyverse)

customer_data <- read_csv("data/customer_data.csv")
customer_data
```
:::

## Filter Observations

Polars **DataFrames** have methods that mirror SQL. DataFrames are still composed of columns called **Series**, however, unlike Pandas DataFrames, Polars DataFrames don't have a **row index** (so no need to `.reset_index()`).

Additionally, instead of relying on Pandas' `.loc[]` **property**, Polars includes function-like **expressions** like `pl.col('column_name')`.

::: {.panel-tabset .scrollable}
## Polars

```{python}
customer_data.filter(pl.col('college_degree') == 'Yes')
customer_data.filter(pl.col('region') != 'West')
customer_data.filter(pl.col('gender') != 'Female', pl.col('income') > 70000)
```

## Pandas

```{python}
customer_data_pd.loc[customer_data_pd['college_degree'] == 'Yes']
customer_data_pd.loc[customer_data_pd['region'] != 'West']
customer_data_pd.loc[(customer_data_pd['gender'] != 'Female') & (customer_data_pd['income'] > 70000)]
```

## R

```{r}
filter(customer_data, college_degree == "Yes")
filter(customer_data, region != "West")
filter(customer_data, gender == "Female", income > 70000)
```
:::

## Slice Observations

The parameters for Polars' `.slice()` method are the start index and the length.

We similarly don't need to rely on Pandas' `.iloc[]` property.

::: {.panel-tabset .scrollable}
## Polars

```{python}
customer_data.slice(0, 5)
```

## Pandas

```{python}
customer_data_pd.iloc[0:5]
```

## R

```{r}
slice(customer_data, 1:5)
```
:::

## Sort Observations

To reiterate, instead of using `[ ]` like in Pandas, in Polars we rely on expressions like `pl.col()`.

::: {.panel-tabset .scrollable}
## Polars

```{python}
customer_data.sort(pl.col('birth_year'))
customer_data.sort(pl.col('birth_year'), descending = True)
```

## Pandas

```{python}
customer_data_pd.sort_values('birth_year')
customer_data_pd.sort_values('birth_year', ascending = False)
```

## R

```{r}
arrange(customer_data, birth_year)
arrange(customer_data, desc(birth_year))
```
:::

## Select Variables

Polars separates out `.filter()` and `.select()` that are combined in Pandas' `.loc[]`.

::: {.panel-tabset .scrollable}
## Polars

```{python}
customer_data.select(pl.col('region'), pl.col('review_text'))
customer_data.select(pl.col(['region', 'review_text']))
```

## Pandas

```{python}
customer_data_pd.loc[:, ['region', 'review_text']]
```

## R

```{r}
select(customer_data, region, review_text)
```
:::

## Add Variables

Polars is actually a query language, like SQL. So it's not surprising to see methods with names that more closely mirror queries, like the `.with_columns()` method.

::: {.panel-tabset .scrollable}
## Polars

```{python}
customer_data.with_columns(income_new = pl.col('income') / 1000)
```

## Pandas

```{python}
customer_data_pd.assign(income_new = customer_data_pd['income'] / 1000)
```

## R

```{r}
mutate(customer_data, income = income / 1000)
```
:::

## Join Data Frames

Joins are straightforward.

::: {.panel-tabset .scrollable}
## Polars

```{python}
store_transactions = pl.read_csv('data/store_transactions.csv')
store_transactions

customer_data.join(store_transactions, on = 'customer_id', how = 'left')
```

## Pandas

```{python}
store_transactions_pd = pd.read_csv('data/store_transactions.csv')
store_transactions_pd

customer_data_pd.set_index('customer_id').join(store_transactions_pd.set_index('customer_id'))
```

## R

```{r}
store_transactions <- read_csv("store_transactions.csv")
store_transactions

left_join(customer_data, store_transactions, join_by(customer_id))
```
:::

## Consecutive Lines of Code

While possible with Python code generally, Polars especially embraces writing consecutive lines of code using **method chaining**. Note that:

- The entire chain needs to be surrounded with `( )`
- Each line *starts* with `.`
- You run the whole block of code at once

::: {.panel-tabset .scrollable}
## Polars

```{python}
(customer_data
  .join(store_transactions, on='customer_id', how='left')
  .filter(pl.col('region') == 'West', pl.col('feb_2005') == pl.col('feb_2005').max())
  .with_columns(age = 2024 - pl.col('birth_year'))
  .select(pl.col(['age', 'feb_2005']))
  .sort(pl.col('age'), descending=True)
  .slice(0, 1)
)
```

## Pandas

```{python}
crm_data_pd = (customer_data_pd
  .set_index('customer_id')
  .join(store_transactions_pd.set_index('customer_id'))
)

(crm_data_pd
  .loc[(crm_data_pd['region'] == 'West') & (crm_data_pd['feb_2005'] == crm_data_pd['feb_2005'].max())]
  .assign(age = 2024 - crm_data_pd['birth_year'])
  .loc[:, ['age', 'feb_2005']]
  .sort_values('age', ascending = False)
  .iloc[0:1]
)
```

## R

```{r}
customer_data |> 
  left_join(store_transactions, join_by(customer_id)) |> 
  filter(region == "West", feb_2005 == max(feb_2005)) |> 
  mutate(age = 2024 - birth_year) |> 
  select(age, feb_2005) |> 
  arrange(desc(age)) |> 
  slice(1)
```
:::

## Summarize Discrete Data

::: {.panel-tabset .scrollable}
## Polars

```{python}
(customer_data
  .group_by(pl.col('region'))
  .agg(n = pl.len())
)

(customer_data
  .group_by(pl.col(['region', 'college_degree']))
  .agg(n = pl.len())
)
```

## Pandas

```{python}
(customer_data_pd
  .value_counts('region')
)

(customer_data_pd
  .value_counts(['region', 'college_degree'])
)
```

## R

```{r}
customer_data |> 
  count(region)

customer_data |> 
  count(region, college_degree)
```
:::

## Summarize Continuous Data

::: {.panel-tabset .scrollable}
## Polars

```{python}
(customer_data
  .select(pl.col('income'))
  .mean()
)

(customer_data
  .select(pl.col(['income', 'credit']))
  .mean()
)
```

## Pandas

```{python}
(customer_data_pd
  .loc[:, ['income']]
  .mean()
)

(customer_data_pd
  .loc[:, ['income', 'credit']]
  .mean()
)
```

## R

```{r}
customer_data |>
  summarize(avg_income = mean(income))

customer_data |>
  summarize(
    avg_income = mean(income),
    avg_credit = mean(credit)
  )
```
:::

## Summarize Discrete and Continuous Data

::: {.panel-tabset .scrollable}
## Polars

```{python}
(customer_data
  .group_by(pl.col(['gender', 'region']))
  .agg(
    avg_income = pl.col('income').mean(), 
    avg_credit = pl.col('credit').mean()
  )
  .sort(pl.col('avg_income'), descending = True)
)
```

## Pandas

```{python}
(customer_data_pd
 .groupby(['gender', 'region'])
 .agg(
   avg_income = ('income', 'mean'), 
   avg_credit = ('credit', 'mean')
  )
 .sort_values('avg_income', ascending = False)
)
```

## R

```{r}
customer_data |>
  group_by(gender, region) |>
  summarize(
    avg_income = mean(income),
    avg_credit = mean(credit)
  ) |> 
  arrange(desc(avg_income))
```
:::

# Don't forget lazy evaluation!

## Resources

- [Lazy API](https://docs.pola.rs/user-guide/concepts/lazy-api/)
- [Modern Polars](https://kevinheavey.github.io/modern-polars/)
- [Polars for Data Analysis in Python](https://www.youtube.com/watch?v=5V_MvnwTVwc)
- [Understanding Expressions when you're used to pandas](https://www.youtube.com/watch?v=kPtUPe5Egak)
- [Polarsâ€™ Rgonomic Patterns](https://emilyriederer.netlify.app/post/py-rgo-polars/)

# Thank you! {background-color="#486790"}

[marc.dotson@usu.edu](mailto:marc.dotson@usu.edu)  
[github.com/marcdotson](https://github.com/marcdotson)  
[occasionaldivergences.com](https://occasionaldivergences.com)

